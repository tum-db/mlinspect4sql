{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Showcase of the \"to_sql\" functionality of mlinspect\n",
    "\n",
    "It will be shown how parts of the original mlinspect example pipelines\n",
    "\"healthcare\" and \"compas\" will be inspected using the additional \"to_sql\"\n",
    "functionality."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First install the required packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /home/luca/Documents/Bachelorarbeit/mlinspect/venv/lib/python3.8/site-packages (8.10.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /home/luca/Documents/Bachelorarbeit/mlinspect/venv/lib/python3.8/site-packages (from faker) (2.8.2)\r\n",
      "Requirement already satisfied: text-unidecode==1.3 in /home/luca/Documents/Bachelorarbeit/mlinspect/venv/lib/python3.8/site-packages (from faker) (1.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/luca/Documents/Bachelorarbeit/mlinspect/venv/lib/python3.8/site-packages (from python-dateutil>=2.4->faker) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Install the pip packages in the current Jupyter kernel\n",
    "import pathlib\n",
    "import sys\n",
    "!{sys.executable} -m pip install faker"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Some parameters you might want to set:#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from mlinspect.to_sql.dbms_connectors.postgresql_connector import PostgresqlConnector\n",
    "from mlinspect.to_sql.dbms_connectors.umbra_connector import UmbraConnector\n",
    "from pandas_connector import PandasConnector\n",
    "from _benchmark_utility import REPETITIONS, plot_compare, ROOT_DIR\n",
    "from _code_as_string import Join, GroupBy, Selection, Projection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "UMBRA_DIR = r\"/home/luca/Documents/Bachelorarbeit/umbra-students\"\n",
    "DO_CLEANUP= True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Operation performance comparison (not exhaustive)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No user with password configured. For initial setup, connect via a domain socket:\n",
      "   psql -h /tmp -U postgres\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION: 0 - for table size of: 100\n",
      "Executing Query in Umbra...\n",
      "Done in 0.0002094!\n",
      "Executing Query in Postgres...\n",
      "Done in 0.10189999999999999!\n",
      "Executing Query in Pandas...\n",
      "Done in 5.210922300102538!\n",
      "Executing Query in Umbra...\n",
      "Done in 7.38e-05!\n",
      "Executing Query in Postgres...\n",
      "Done in 0.033400000000000006!\n",
      "Executing Query in Pandas...\n",
      "Done in 2.499655899919162!\n",
      "Executing Query in Umbra...\n",
      "Done in 0.00015319999999999998!\n",
      "Executing Query in Postgres...\n",
      "Done in 0.026500000000000003!\n",
      "Executing Query in Pandas...\n",
      "Done in 2.9723665000346955!\n",
      "Executing Query in Umbra...\n",
      "Done in 0.0003685!\n",
      "Executing Query in Postgres...\n",
      "Done in 0.091!\n",
      "Executing Query in Pandas...\n",
      "Done in 5.4432681999969645!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Killed\n",
      "No user with password configured. For initial setup, connect via a domain socket:\n",
      "   psql -h /tmp -U postgres\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION: 1 - for table size of: 1000\n",
      "Executing Query in Umbra...\n",
      "Done in 0.0007430000000000001!\n",
      "Executing Query in Postgres...\n",
      "Done in 3.4902!\n",
      "Executing Query in Pandas...\n",
      "Done in 6.294666800022242!\n",
      "Executing Query in Umbra...\n",
      "Done in 0.0001651!\n",
      "Executing Query in Postgres...\n",
      "Done in 0.2374!\n",
      "Executing Query in Pandas...\n",
      "Done in 2.800366700103041!\n",
      "Executing Query in Umbra...\n",
      "Done in 0.00013700000000000002!\n",
      "Executing Query in Postgres...\n",
      "Done in 0.2969!\n",
      "Executing Query in Pandas...\n",
      "Done in 1.7781336000552983!\n",
      "Executing Query in Umbra...\n",
      "Done in 0.0003965!\n",
      "Executing Query in Postgres...\n",
      "Done in 0.6638999999999999!\n",
      "Executing Query in Pandas...\n",
      "Done in 4.8582624998743995!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Killed\n",
      "No user with password configured. For initial setup, connect via a domain socket:\n",
      "   psql -h /tmp -U postgres\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION: 2 - for table size of: 10000\n",
      "Executing Query in Umbra...\n",
      "Done in 0.0031942999999999997!\n",
      "Executing Query in Postgres...\n",
      "Done in 31.891199999999998!\n",
      "Executing Query in Pandas...\n",
      "Done in 19.66948280005454!\n",
      "Executing Query in Umbra...\n",
      "Done in 0.0008033999999999999!\n",
      "Executing Query in Postgres...\n",
      "Done in 1.3955000000000002!\n",
      "Executing Query in Pandas...\n",
      "Done in 5.128223400060961!\n",
      "Executing Query in Umbra...\n",
      "Done in 0.0004465!\n",
      "Executing Query in Postgres...\n",
      "Done in 1.4773!\n",
      "Executing Query in Pandas...\n",
      "Done in 5.134220800027833!\n",
      "Executing Query in Umbra...\n",
      "Done in 0.0007681999999999999!\n",
      "Executing Query in Postgres...\n",
      "Done in 2.9023!\n",
      "Executing Query in Pandas...\n",
      "Done in 8.485655100048461!\n"
     ]
    }
   ],
   "source": [
    "# Based on mlinspect benchmarks.\n",
    "t1_name = \"histories\"\n",
    "t2_name = \"patients\"\n",
    "\n",
    "operations = [\"Join\", \"Select\", \"Project\", \"GroupBy\"]\n",
    "\n",
    "files = []\n",
    "for i in REPETITIONS:\n",
    "    path_table1 = ROOT_DIR / f\"data_generation/generated_csv/healthcare_histories_generated_{i}.csv\"\n",
    "    path_table2 = ROOT_DIR / f\"data_generation/generated_csv/healthcare_patients_generated_{i}.csv\"\n",
    "    files.append((path_table1, path_table2))\n",
    "\n",
    "umbra_times = [[] for _ in operations]\n",
    "postgres_times = [[] for _ in operations]\n",
    "pandas_times = [[] for _ in operations]\n",
    "\n",
    "postgres = PostgresqlConnector(dbname=\"healthcare_benchmark\", user=\"luca\", password=\"password\", port=5432,\n",
    "                               host=\"localhost\")\n",
    "pandas = PandasConnector()\n",
    "\n",
    "for i, (table1, table2) in enumerate(files):\n",
    "    umbra = UmbraConnector(dbname=\"\", user=\"postgres\", password=\" \", port=5433, host=\"/tmp/\",\n",
    "                           umbra_dir=UMBRA_DIR)\n",
    "\n",
    "    umbra.add_csv(table_name=t2_name, path_to_csv=table2, null_symbols=[\"?\"], delimiter=\",\", header=True)\n",
    "    umbra.add_csv(table_name=t1_name, path_to_csv=table1, null_symbols=[\"?\"], delimiter=\",\", header=True)\n",
    "\n",
    "    postgres.add_csv(table_name=t2_name, path_to_csv=table2, null_symbols=[\"?\"], delimiter=\",\", header=True)\n",
    "    postgres.add_csv(table_name=t1_name, path_to_csv=table1, null_symbols=[\"?\"], delimiter=\",\", header=True)\n",
    "\n",
    "    print(f\"ITERATION: {i} - for table size of: {10 ** (i + 2)}\")\n",
    "    repetitions = 10\n",
    "\n",
    "    input_join = t1_name, t2_name, \"ssn\"\n",
    "    umbra_times[0].append(umbra.benchmark_run(Join.get_sql_code(*input_join), repetitions))\n",
    "    postgres_times[0].append(postgres.benchmark_run(Join.get_sql_code(*input_join), repetitions))\n",
    "    pandas_times[0].append(\n",
    "        pandas.benchmark_run(Join.get_pandas_code(table1, table2, \"ssn\"), repetitions=repetitions))\n",
    "\n",
    "    input_sel = t1_name, \"complications\", \">\", \"5\"\n",
    "    umbra_times[1].append(umbra.benchmark_run(Selection.get_sql_code(*input_sel), repetitions))\n",
    "    postgres_times[1].append(postgres.benchmark_run(Selection.get_sql_code(*input_sel), repetitions))\n",
    "    pandas_times[1].append(\n",
    "        pandas.benchmark_run(Selection.get_pandas_code(table1, \"complications\", \">\", \"5\"),\n",
    "                             repetitions=repetitions))\n",
    "\n",
    "    input_project = t1_name, \"smoker\"\n",
    "    umbra_times[2].append(umbra.benchmark_run(Projection.get_sql_code(*input_project), repetitions))\n",
    "    postgres_times[2].append(postgres.benchmark_run(Projection.get_sql_code(*input_project), repetitions))\n",
    "    pandas_times[2].append(\n",
    "        pandas.benchmark_run(Projection.get_pandas_code(table1, \"smoker\"), repetitions=repetitions))\n",
    "\n",
    "    input_project = t1_name, \"smoker\", \"complications\", \"AVG\"\n",
    "    umbra_times[3].append(umbra.benchmark_run(GroupBy.get_sql_code(*input_project), repetitions))\n",
    "    postgres_times[3].append(postgres.benchmark_run(GroupBy.get_sql_code(*input_project), repetitions))\n",
    "    pandas_times[3].append(\n",
    "        pandas.benchmark_run(GroupBy.get_pandas_code(table1, \"smoker\", \"complications\", \"mean\"),\n",
    "                             repetitions=repetitions))\n",
    "    # in the end we have 3 lists == [[*joins*][*selections*][*projections*]]\n",
    "\n",
    "names = [\"Umbra\", \"Postgresql\", \"Pandas\"]\n",
    "for i, title in enumerate(operations):\n",
    "    table = [umbra_times[i], postgres_times[i], pandas_times[i]]\n",
    "    plot = plot_compare(title, REPETITIONS, all_y=table, all_y_names=names, save=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The original results:\n",
    "**Join**:\n",
    "\n",
    "![](./plots/Join.png)\n",
    "\n",
    "**GroupBy**:\n",
    "\n",
    "![](./plots/GroupBy.png)\n",
    "\n",
    "**Select**:\n",
    "\n",
    "![](./plots/Select.png)\n",
    "\n",
    "**Project**:\n",
    "\n",
    "![](./plots/Project.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Generation\n",
    "\n",
    "To be able to benchmark and compare the different approaches, some datasets\n",
    "will need to be generated before. The datasets are just and expansion of the\n",
    "original ones."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_72258/1127571345.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mdata_generation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compas_data_generation\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgenerate_compas_dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mdata_generation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_healthcare_data_generation\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgenerate_healthcare_dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mcompas_tain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcompas_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mgenerate_compas_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mhealthcare_histories\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhealthcare_patients\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mgenerate_healthcare_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from data_generation._compas_data_generation import generate_compas_dataset\n",
    "from data_generation._healthcare_data_generation import generate_healthcare_dataset\n",
    "\n",
    "compas_tain, compas_test = zip(*generate_compas_dataset())\n",
    "healthcare_histories, healthcare_patients = zip(*generate_healthcare_dataset())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Clean_up:\n",
    "\n",
    "if DO_CLEANUP:\n",
    "    plot_dir = ROOT_DIR / f\"plots\"\n",
    "    [f.unlink() for f in plot_dir.glob(\"*_*.png\") if f.is_file()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}